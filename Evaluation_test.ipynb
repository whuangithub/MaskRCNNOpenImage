{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# the trained model is saved in the 'mask_rcnn_openimage_cfg_0040.h5'\n",
    "# copy it to the working directory\n",
    "\n",
    "####################################################################\n",
    "#Evaluate\n",
    "\n",
    "# mean average precision: mAP\n",
    "# https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173\n",
    "\n",
    "# IoU => Precison & Recall => PR curve => AP => mAP (mean of AP of all classes)\n",
    "\n",
    "# I met\n",
    "# Error : Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n",
    "# https://github.com/tensorflow/tensorflow/issues/24828\n",
    "# Suggests the following solution\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config0 = ConfigProto()\n",
    "config0.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config0)\n",
    "\n",
    "# evaluate the mask rcnn model on the kangaroo dataset\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "import csv\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/HDD1/Downloads/OpenImageV5/Train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/HDD1/Downloads/OpenImageV5/MyData/'\n",
    "# read the list of image IDs\n",
    "with open(data_dir+'training_image_list.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_image_list = list(reader)[0]\n",
    "with open(data_dir+'validation_image_list.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    validation_image_list = list(reader)[0]\n",
    "with open(data_dir+'test_image_list.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    test_image_list = list(reader)[0]\n",
    "\n",
    "with open(data_dir+'all_image_list.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    all_image_list = list(reader)[0]\n",
    "\n",
    "# read the boxes\n",
    "training_dataset = pd.read_csv(data_dir+'training_dataset.csv')\n",
    "validation_dataset = pd.read_csv(data_dir+'validation_dataset.csv')\n",
    "test_dataset = pd.read_csv(data_dir+'test_dataset.csv')\n",
    "all_dataset = pd.read_csv(data_dir+'all_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the classs imformation\n",
    "with open(data_dir+'class-descriptions-boxable.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    class_file = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dataset class\n",
    "# based on the Dataset class\n",
    "class OpenImageDataset(Dataset):\n",
    "    def load_dataset(self,dataset_dir,is_train=True):\n",
    "        #define one class\n",
    "        # add_class is built in the original class\n",
    "        for i in range(len(class_file)):\n",
    "            self.add_class(\"OpenImage\",i+1,class_file[i][1])\n",
    "        \n",
    "        if is_train:\n",
    "            # it takes too long to evaluate the entire dataset, \n",
    "            # so I just set the size of the evaluation to a small number\n",
    "            for image_id in range(len(training_image_list)*0+10000):\n",
    "                img_path = image_dir + all_image_list[image_id] + \".jpg\"\n",
    "                self.add_image('OpenImage',image_id=all_image_list[image_id],path=img_path)\n",
    "        if not is_train:\n",
    "            # because we do not change the hyperparameters in the project\n",
    "            # I use the valiataiton and test set as test set\n",
    "            for image_id in range(len(training_image_list),len(all_image_list)\\\n",
    "                                  *0+len(training_image_list)+10000):\n",
    "                img_path = image_dir + all_image_list[image_id] + \".jpg\"\n",
    "                self.add_image('OpenImage',image_id=all_image_list[image_id],path=img_path)\n",
    "            \n",
    "    # define a function to extract the boxes from csv[ done 11.11]\n",
    "    def extract_boxes(self,image_name):\n",
    "        # find the lines with imageID\n",
    "        image_data = all_dataset.loc[all_dataset['ImageID']==image_name]\n",
    "        \n",
    "        # extract image dimensions\n",
    "        image=Image.open(image_dir+image_name+'.jpg')\n",
    "        width,height = image.size\n",
    "        \n",
    "        # extract all the bounding boxes\n",
    "        boxes = list()\n",
    "        class_label = list()\n",
    "        for index,row in image_data.iterrows():\n",
    "            #because in this dataset, XMin is shown in numbers like 0.234\n",
    "            xmin = round(width*row['XMin'])\n",
    "            ymin = round(height*row['YMin'])\n",
    "            xmax = round(width*row['XMax'])\n",
    "            ymax = round(height*row['YMax'])\n",
    "            boxes.append([xmin,ymin,xmax,ymax])\n",
    "            class_label.append(row['LabelName'])\n",
    "        \n",
    "        # obtain class id \n",
    "        class_ids = list()\n",
    "        for label in class_label:\n",
    "            # search for the label in first column of the file\n",
    "            index = np.array(class_file)[:,0].tolist().index(label)\n",
    "            class_ids.append(class_file[index][1])\n",
    "        \n",
    "        return boxes, width, height, class_ids\n",
    "    \n",
    "    def load_mask(self,image_id_order):\n",
    "        # from image_id to image_name\n",
    "        info = self.image_info[image_id_order]\n",
    "        image_name = info['id']\n",
    "        # call extract_boxes tp get the bboxes and w,h\n",
    "        boxes,w,h,class_ids_name = self.extract_boxes(image_name)\n",
    "        # create masks\n",
    "        masks = zeros([h,w,len(boxes)]) # could be multiple boxes\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            col_start, col_end = box[0],box[2]\n",
    "            row_start, row_end = box[1],box[3]\n",
    "            masks[row_start:row_end,col_start:col_end,i] = 1\n",
    "            # record the class of each box\n",
    "            class_ids.append(self.class_names.index(class_ids_name[i]))\n",
    "        return masks, asarray(class_ids,dtype='int32')\n",
    "    \n",
    "    # image_id must be int\n",
    "    def image_reference(self,image_id_order):\n",
    "        info = self.image_info[image_id_order]\n",
    "        return info['path']\n",
    "    \n",
    "    # I met a problem that the sizes of predicted masks and true masks do not match\n",
    "    # finally i found it because I did not import the image and mask data from a same file\n",
    "    \n",
    "    # one should pay attention to this load_mask method and image reference method\n",
    "    # make sure that they refer to a same image\n",
    "    # better to use identical functions/structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "# define a configuration for the model\n",
    "class PredictionConfig(Config):\n",
    "    # GIve the configutation a recognizable name\n",
    "    NAME = \"OpenImage_cfg\"\n",
    "    #Number of classes \n",
    "    NUM_CLASSES = 1 + len(class_file)\n",
    "    # seems that in evaluation,GPU_COUNT*IMAGES_PER_GPU has to be one?\n",
    "    # bug? https://github.com/matterport/Mask_RCNN/pull/1082\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "#     Actually using this \"none\" is better for this dataset, because some of the images \n",
    "#     has a large width to height ratio. See the config.py  \n",
    "#     IMAGE_RESIZE_MODE = \"none\"\n",
    "    \n",
    "config = PredictionConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "    APs = list()\n",
    "    for image_id in dataset.image_ids:\n",
    "        # load image, bounding boxes and masks for the image id\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "        # convert pixel values (e.g. center)\n",
    "        # why do we need this\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)\n",
    "        # extract results for first sample\n",
    "        r = yhat[0]\n",
    "        # calculate statistics, including AP\n",
    "        AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        \n",
    "        # store\n",
    "        APs.append(AP)\n",
    "    # calculate the mean AP across all images\n",
    "    mAP = mean(APs)\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10000\n",
      "Test: 10000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /HDD1/Code/MaskRCNNOpenImage/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /HDD1/Code/MaskRCNNOpenImage/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /HDD1/Code/MaskRCNNOpenImage/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /HDD1/Code/MaskRCNNOpenImage/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From /HDD1/Code/MaskRCNNOpenImage/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /HDD1/Code/MaskRCNNOpenImage/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the train dataset\n",
    "train_set = OpenImageDataset()\n",
    "train_set.load_dataset('OpenImage', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# load the test dataset\n",
    "test_set = OpenImageDataset()\n",
    "test_set.load_dataset('OpenImage', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=config)\n",
    "# load model weights\n",
    "model.load_weights('mask_rcnn_openimage_cfg_0040.h5', by_name=True)\n",
    "# evaluate model on training dataset\n",
    "train_mAP = evaluate_model(train_set, model, config)\n",
    "print(\"Train mAP: %.3f\" % train_mAP)\n",
    "# evaluate model on test dataset\n",
    "test_mAP = evaluate_model(test_set, model,config)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
